# Building Images

## Images and Containers

An image includes everything an application needs to run:

- a cut-down OS
- third-party libraries
- application files
- environment variables
- and much more

A container is like a virtual-machine:

- provides an isolated environment for executing an application
- can be stopped and restarted
- is just a precess

## Dockerfile Instructions

A Dockerfile contains instructions for building an image

- FROM
- WORKDIR
- COPY
- ADD
- RUN
- ENV
- EXPOSE
- USER
- CMD
- ENTRYPOINT

## Choosing the Right Base Image

**FROM** is used to specify the base image it can be an OS or an OS plus a runtime environment.
for example if you're a python developer you start with **Python** image or **Node** image for Javascript developer.

Don't blindly choose images always do your research

**Note**: `FROM node:latest` do not use **latest** tag, once you're done with your project there might be another new version for the base image and that has the potential to cause problems than good.

there might be different builds for the base image based on the OS and CPU architecture, you don't need to worry about it since **docker** toke care of that nad when you pull an image it automatically chooses the right one.

### Searching for a Base image

1. Go to DockerHub and search for the base image like "node" and "python"
2. Click on the official image
3. Select the tags tab and filter the images based on subsystem link "alpine", "arch"
4. Choose the one you are happy with "docker pull node:23.3.0-alpine3.20" but don't execute it right away
5. In you're **Dockerfile** use this part **node:23.3.0-alpine3.20** like so `FROM node:23.3.0-alpine3.20`

### Building an Image

After choosing the base image and versions with this command in your Dockerfile `FROM node:23.3.0-alpine3.20`, open up terminal and run `docker build -t react-app .`

- `docker build` to build an image
- `-t react-app` to give it a tag **react-app**
- `.` is the path to **Dockerfile** in our case it's in our current directory

**Note**: Make sure **docker desktop** is open and **docker engine** is running!

when you run the above command docker downloads the files and build your image.

you can check that by running `docker image ls` or `docker images`

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker images
REPOSITORY         TAG       IMAGE ID       CREATED       SIZE
react-app          latest    3bce6930aaa0   12 days ago   161MB
hello-docker-new   latest    8c4284648ad1   6 weeks ago   158MB
hello-docker       latest    ee4aa78d435d   6 weeks ago   158MB
ubuntu             latest    59ab366372d5   7 weeks ago   78.1MB
```

### Running the Image

To run the image you execute `docker run -it react-app` to open it up in the interactive mode.
but that opens a **Node** environment which you can write Js code and will be executed just like the **Browser console** and it's not what we want, we want to start our react-app.

at the end of run command we can specify the command to run when starting this container,
run `docker run -it react-app bash` here we want to run **bash**, which throws the following error

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app bash
node:internal/modules/cjs/loader:1242
  throw err;
  ^

Error: Cannot find module '/bash'
    at Function._resolveFilename (node:internal/modules/cjs/loader:1239:15)
    at Function._load (node:internal/modules/cjs/loader:1064:27)
    at TracingChannel.traceSync (node:diagnostics_channel:322:14)
    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:170:5)
    at node:internal/main/run_main_module:36:49 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}

Node.js v23.3.0

```

and that is because **alpine linux** is very small distribution and doesn't come with bash installed. instead run `docker run -it react-app sh` to open **shell** which is standard for all linux distributions.

here is the result and we can check Node version

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app sh
/ # ls
bin    dev    etc    home   lib    media  mnt    opt    proc   root   run    sbin   srv    sys    tmp    usr    var
/ # node --version
v23.3.0
/ #
```

but we don't have our application files! yet.

## Copying Files and Directories

Now that we have a base image we need to copy our application files into the image, so for that we have `COPY` and `ADD` they have the same syntax but `ADD` has a couple more features.

`COPY` with this we can copy one or more files/directories from current directory into the image. wa can't copy files/directories from outside current directory (where the Dockerfile is located).

that is because in `docker build -t react-app .` command we used `.` (current directory), when we run this command **docker client** sends the contents of **current directory** to **docker engine** which is called `build context`, so **docker client** sends **build context** to **docker engine** and then **docker engine** start executing commands inside **Dockerfile** one by one, this way docker engine does't have access to the files/directories outside this directory.

```Dockerfile
FROM node:23.3.0-alpine3.20
# -------------------------- about source -------------------------
# Copy files or folders from source to the dest path in the image's filesystem.
# COPY source dest

# copying package.json into /app directory in image's filesystem, will be created if doesn't exist
COPY package.json /app

# When using COPY with more than one source file, the destination must be a directory and end with a / or a \
COPY package.json README.md /app/

# Or use a pattern
COPY package*.json /app

# Copy all files and directories from source to dest
COPY . /app
# ------------------------------ about destination ----------------------

# here we use absolute path "/app" for the destination
COPY . /app

# we can only use relative path when the "WORKDIR" is set
# when you set WORKDIR all the instruction coming after this will be executed inside this working directory
WORKDIR /app
# copy all files/directories from current working directory into "/app" working directory
COPY . .

Note: if the file name has space like (hello world.txt) we should use this syntax ["","",""]
where each string represents an argument of COPY command, `COPY ["hello world.txt", "."]`

COPY ["hello world.txt", "."]
```

we also have ADD command

```Dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
# add a file from a URL, if you have access to it
ADD http://.../file.txt .

# the other feature is that you can add a compress file and ADD will extracted it
ADD file.zip .
```

**Note**: It's best to use **COPY** command over **ADD** unless you need to add a file from a URL or add a compressed file.

Now run

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app sh
/app # ls
Dockerfile         eslint.config.js   node_modules       package.json       src
README.md          index.html         package-lock.json  public             vite.config.js
/app #
```

## Excluding Files and Directories

When building docker images there are files that doesn't need to be included in the built image, mostly because it can be easily generated in any machine and to speed up our build and deployment process. meet `.dockerignore` file containing all the files and directories to be excluded, it should be in the root directory of your project just like `.gitignore` file.

```dockerignore
node_modules
```

now that we have `.dockerignore` file excluding `node_modules` run `docker build -t react-app .` to build our image without `node_modules` (the size is significantly reduced).

now we need to run `docker run -it react-app sh` and then in the shell session run `npm install` to install all the dependencies, since we excluded the `.dockerignore` file.

## Running Commands

Now to install our dependencies we should include `RUN` command in our Dockerfile

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install

```

basically wit `RUN` command we can run any command we could in `terminal`,

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
RUN apt install python -> in case you need to install another package

```

**Note**: alpine distro doesn't have `apt` instead it has `apk` and here is a few commands:

```bash
apk add python3 -> install python version 3
apk update -> to update the installer resources if the installer package is not available
apk add python3 -> run again to install
python3 --version -> check if the package installed successfully
```

but for our react-app project this is the Dockerfile

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
```

## Setting Environment Variables

Quite often we need to define environment variables in our app and you can do so with `ENV`
command in Dockerfile.

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
# new syntax
ENV API_URL=http://api/myapp.com
# old syntax
ENV API_URL http://api/myapp.com

```

**Note**: use the new syntax for defining environment variables to be clear.

now run `docker build -t react-app .` to build our app again

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app sh
/app # printenv
NODE_VERSION=23.3.0
HOSTNAME=fdfe17510384
YARN_VERSION=1.22.22
SHLVL=2
HOME=/root
TERM=xterm
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PWD=/app
API_URL=http://api/myapp.com
/app # printenv API_URL
http://api/myapp.com
/app # echo $API_URL
http://api/myapp.com
```

and as above our environment variable is set for us.

## Exposing Ports

when we run our `react-app` as usual we get `http://localhost:3000`, 3000 port is open to the host (our windows PC) but when we run this app's docker image that port will be open to the container not to the host, basically we can't view the output as usual.

this behavior is useful when we have multiple containers running the same image.

In this situation we need to `EXPOSE` the `3000` port from our container to the host. but this port is not going to be mapped to the host automatically, we need to map it.

first we need to add `EXPOSE` to our dockerfile, to tell what port this container will be listening on.

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
ENV API_URL=http://api/myapp.com
EXPOSE 3000
```
`EXPOSE` command doesn't publish the port on the host, is just a form of documentation that tells us which port this container will eventually be listening on.

## Setting the User

By default Docker runs our applications on the root user with the most privileges, this can open up security holes in our system, to prevent this we need to create a normal user with limited privileges.

create a system user (system users have limited privileges and used for running background precesses), and a group for that user.

```dockerfile
RUN ddgroup -S app && adduser -S -G app app
``` 

then to switch the user use 

```dockerfile
USER app 
```

all the following commands will be executed using this user.