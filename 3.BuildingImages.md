# Building Images

## Images and Containers

An image includes everything an application needs to run:

- a cut-down OS
- third-party libraries
- application files
- environment variables
- and much more

A container is like a virtual-machine:

- provides an isolated environment for executing an application
- can be stopped and restarted
- is just a precess

## Dockerfile Instructions

A Dockerfile contains instructions for building an image

- FROM
- WORKDIR
- COPY
- ADD
- RUN
- ENV
- EXPOSE
- USER
- CMD
- ENTRYPOINT

## Choosing the Right Base Image

**FROM** is used to specify the base image it can be an OS or an OS plus a runtime environment.
for example if you're a python developer you start with **Python** image or **Node** image for Javascript developer.

Don't blindly choose images always do your research

**Note**: `FROM node:latest` do not use **latest** tag, once you're done with your project there might be another new version for the base image and that has the potential to cause problems than good.

there might be different builds for the base image based on the OS and CPU architecture, you don't need to worry about it since **docker** toke care of that nad when you pull an image it automatically chooses the right one.

### Searching for a Base image

1. Go to DockerHub and search for the base image like "node" and "python"
2. Click on the official image
3. Select the tags tab and filter the images based on subsystem link "alpine", "arch"
4. Choose the one you are happy with "docker pull node:23.3.0-alpine3.20" but don't execute it right away
5. In you're **Dockerfile** use this part **node:23.3.0-alpine3.20** like so `FROM node:23.3.0-alpine3.20`

### Building an Image

After choosing the base image and versions with this command in your Dockerfile `FROM node:23.3.0-alpine3.20`, open up terminal and run `docker build -t react-app .`

- `docker build` to build an image
- `-t react-app` to give it a tag **react-app**
- `.` is the path to **Dockerfile** in our case it's in our current directory

**Note**: Make sure **docker desktop** is open and **docker engine** is running!

when you run the above command docker downloads the files and build your image.

you can check that by running `docker image ls` or `docker images`

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker images
REPOSITORY         TAG       IMAGE ID       CREATED       SIZE
react-app          latest    3bce6930aaa0   12 days ago   161MB
hello-docker-new   latest    8c4284648ad1   6 weeks ago   158MB
hello-docker       latest    ee4aa78d435d   6 weeks ago   158MB
ubuntu             latest    59ab366372d5   7 weeks ago   78.1MB
```

### Running the Image

To run the image you execute `docker run -it react-app` to open it up in the interactive mode.
but that opens a **Node** environment which you can write Js code and will be executed just like the **Browser console** and it's not what we want, we want to start our react-app.

at the end of run command we can specify the command to run when starting this container,
run `docker run -it react-app bash` here we want to run **bash**, which throws the following error

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app bash
node:internal/modules/cjs/loader:1242
  throw err;
  ^

Error: Cannot find module '/bash'
    at Function._resolveFilename (node:internal/modules/cjs/loader:1239:15)
    at Function._load (node:internal/modules/cjs/loader:1064:27)
    at TracingChannel.traceSync (node:diagnostics_channel:322:14)
    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:170:5)
    at node:internal/main/run_main_module:36:49 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}

Node.js v23.3.0

```

and that is because **alpine linux** is very small distribution and doesn't come with bash installed. instead run `docker run -it react-app sh` to open **shell** which is standard for all linux distributions.

here is the result and we can check Node version

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app sh
/ # ls
bin    dev    etc    home   lib    media  mnt    opt    proc   root   run    sbin   srv    sys    tmp    usr    var
/ # node --version
v23.3.0
/ #
```

but we don't have our application files! yet.

## Copying Files and Directories

Now that we have a base image we need to copy our application files into the image, so for that we have `COPY` and `ADD` they have the same syntax but `ADD` has a couple more features.

`COPY` with this we can copy one or more files/directories from current directory into the image. wa can't copy files/directories from outside current directory (where the Dockerfile is located).

that is because in `docker build -t react-app .` command we used `.` (current directory), when we run this command **docker client** sends the contents of **current directory** to **docker engine** which is called `build context`, so **docker client** sends **build context** to **docker engine** and then **docker engine** start executing commands inside **Dockerfile** one by one, this way docker engine does't have access to the files/directories outside this directory.

```Dockerfile
FROM node:23.3.0-alpine3.20
# -------------------------- about source -------------------------
# Copy files or folders from source to the dest path in the image's filesystem.
# COPY source dest

# copying package.json into /app directory in image's filesystem, will be created if doesn't exist
COPY package.json /app

# When using COPY with more than one source file, the destination must be a directory and end with a / or a \
COPY package.json README.md /app/

# Or use a pattern
COPY package*.json /app

# Copy all files and directories from source to dest
COPY . /app
# ------------------------------ about destination ----------------------

# here we use absolute path "/app" for the destination
COPY . /app

# we can only use relative path when the "WORKDIR" is set
# when you set WORKDIR all the instruction coming after this will be executed inside this working directory
WORKDIR /app
# copy all files/directories from current working directory into "/app" working directory
COPY . .

Note: if the file name has space like (hello world.txt) we should use this syntax ["","",""]
where each string represents an argument of COPY command, `COPY ["hello world.txt", "."]`

COPY ["hello world.txt", "."]
```

we also have ADD command

```Dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
# add a file from a URL, if you have access to it
ADD http://.../file.txt .

# the other feature is that you can add a compress file and ADD will extracted it
ADD file.zip .
```

**Note**: It's best to use **COPY** command over **ADD** unless you need to add a file from a URL or add a compressed file.

Now run

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app sh
/app # ls
Dockerfile         eslint.config.js   node_modules       package.json       src
README.md          index.html         package-lock.json  public             vite.config.js
/app #
```

## Excluding Files and Directories

When building docker images there are files that doesn't need to be included in the built image, mostly because it can be easily generated in any machine and to speed up our build and deployment process. meet `.dockerignore` file containing all the files and directories to be excluded, it should be in the root directory of your project just like `.gitignore` file.

```dockerignore
node_modules
```

now that we have `.dockerignore` file excluding `node_modules` run `docker build -t react-app .` to build our image without `node_modules` (the size is significantly reduced).

now we need to run `docker run -it react-app sh` and then in the shell session run `npm install` to install all the dependencies, since we excluded the `.dockerignore` file.

## Running Commands

Now to install our dependencies we should include `RUN` command in our Dockerfile

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install

```

basically wit `RUN` command we can run any command we could in `terminal`,

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
RUN apt install python -> in case you need to install another package

```

**Note**: alpine distro doesn't have `apt` instead it has `apk` and here is a few commands:

```bash
apk add python3 -> install python version 3
apk update -> to update the installer resources if the installer package is not available
apk add python3 -> run again to install
python3 --version -> check if the package installed successfully
```

but for our react-app project this is the Dockerfile

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
```

## Setting Environment Variables

Quite often we need to define environment variables in our app and you can do so with `ENV`
command in Dockerfile.

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
# new syntax
ENV API_URL=http://api/myapp.com
# old syntax
ENV API_URL http://api/myapp.com

```

**Note**: use the new syntax for defining environment variables to be clear.

now run `docker build -t react-app .` to build our app again

```bash
PS D:\Courses\Docker\docker-learning\react-app> docker run -it react-app sh
/app # printenv
NODE_VERSION=23.3.0
HOSTNAME=fdfe17510384
YARN_VERSION=1.22.22
SHLVL=2
HOME=/root
TERM=xterm
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PWD=/app
API_URL=http://api/myapp.com
/app # printenv API_URL
http://api/myapp.com
/app # echo $API_URL
http://api/myapp.com
```

and as above our environment variable is set for us.

## Exposing Ports

when we run our `react-app` as usual we get `http://localhost:5173`, 5173 port is open to the host (our windows PC) but when we run this app's docker image that port will be open to the container not to the host, basically we can't view the output as usual.

this behavior is useful when we have multiple containers running the same image.

In this situation we need to `EXPOSE` the `5173` port from our container to the host. but this port is not going to be mapped to the host automatically, we need to map it.

first we need to add `EXPOSE` to our dockerfile, to tell what port this container will be listening on.

```dockerfile
FROM node:23.3.0-alpine3.20
WORKDIR /app
COPY . .
RUN npm install
ENV API_URL=http://api/myapp.com
EXPOSE 5173
```

`EXPOSE` command doesn't publish the port on the host, is just a form of documentation that tells us which port this container will eventually be listening on.

## Setting the User

By default Docker runs our applications on the root user with the most privileges, this can open up security holes in our system, to prevent this we need to create a normal user with limited privileges.

create a system user (system users have limited privileges and used for running background precesses), and a group for that user.

```dockerfile
RUN ddgroup -S app && adduser -S -G app app
```

then to switch the user use

```dockerfile
USER app
```

all the following commands will be executed using this user.

## Defining Entrypoints

Issue with `permission error`

The issue is likely due to the order of commands and how file permissions are handled when the `USER appuser` command is used early in the `Dockerfile`. Here's a breakdown of why your instructor's solution might work in some cases but not in others (like yours).

---

### **Why This Happens**

1. **When `USER appuser` Is Defined Early**:

   - The `WORKDIR /app` command creates the `/app` directory **owned by `appuser`** because the `USER appuser` is already active at that point.
   - However, the `COPY . .` command copies files into `/app`, and the default behavior assigns them to `root`, leaving `appuser` without write permissions.

2. **Why It Worked for Your Instructor**:

   - If their setup ensures the `COPY` step does not overwrite permissions (e.g., because of build cache or host system configuration), the issue might not occur.
   - Alternatively, their `npm install` step might not require creating or modifying files (e.g., if they skipped the `package-lock.json` update due to caching).

3. **Why It Fails for You**:
   - In your case, the `COPY . .` step assigns files to `root`, and `appuser` cannot write to them, causing the `npm install` step to fail.

---

### **The Fix**

To ensure consistent behavior, explicitly adjust permissions **after copying the files**. Here's the corrected `Dockerfile`:

```dockerfile
FROM node:23.3.0-alpine3.20

# Create non-root user and group
RUN addgroup -S appgroup && adduser -S appuser -G appgroup

# Switch to the non-root user
USER appuser

# Set the working directory (created as appuser)
WORKDIR /app

# Switch back to root temporarily for the next steps
USER root

# Copy project files and fix permissions
COPY . .
RUN chown -R appuser:appgroup /app

# Switch back to non-root user
USER appuser

# Install dependencies
RUN npm install

# Set environment variables
ENV API_URL=http://api/myapp.com

# Expose the app port
EXPOSE 3000

# Start the application
CMD ["npm", "start"]
```

---

### **Why This Works**

1. **Permissions Are Adjusted After `COPY`**:

   - The `RUN chown -R appuser:appgroup /app` command ensures all files and directories in `/app` are owned by `appuser`.

2. **Explicit User Switching**:
   - Switching to `USER root` ensures the `COPY` command and `chown` have sufficient permissions.
   - Switching back to `USER appuser` ensures the app runs securely as a non-root user.

---

### **Best Practices**

- Always verify file permissions when copying files into the container.
- Use the `USER` command strategically to avoid unnecessary permission issues.

---

### **Troubleshooting Tips**

1. **Inspect Permissions in the Built Image**:
   Run a shell in the built container to check file ownership:

   ```bash
   docker run -it --rm <image_name> sh
   ls -l /app
   ```

2. **Rebuild Without Cache**:
   If caching causes inconsistent behavior, rebuild the image without using cached layers:

   ```bash
   docker build --no-cache -t react-app .
   ```

---

for now we need to run `docker run react-app npm run dev` in the terminal every time we run our app, which is not ideal and here is the `CMD` command (COMMAND) to run commands in the terminal.

```dockerfile

CMD npm start
# or
CMD npm run dev
```

**Note**: the `CMD` instruction is just to supply the default command, it doesn't make sense to have multiple `CMD` instructions in the dockerfile, even if you supply multiple `CMD` commands only the last one will take effect!

### CMD vs RUN

`RUN` is a build-time instruction, executed at the time of building the image.

`CMD` is a run-time instruction, so it is executed when starting a container.

`CMD` instruction has two forms:

```dockerfile
# shell form
CMD npm start

# Execute form
CMD ["npm", "start"]
```

if you use `shell-form` that command will be executed in a separate shell, but with the `exec-form` we can execute the commands without spinning up another shell session.

here is `ENTRYPOINT` instruction which works similar to `CMD` instruction this this difference that you can't override it, if you need to do so use `--entrypoint` flag.

```dockerfile
ENTRYPOINT [ "npm", "run", "dev" ]
```

```bash


```

`ENTRYPOINT` is used when you know for sure that is the command to be executed whenever we start a container. with the `CMD` instruction we have a bit of flexibility that we can override it without providing any additional flags.

which one to use! it's just the matter of personal preference.